{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27d8db45-849d-41e6-9240-767f67d957d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "NUM_CLASSES=1_000\n",
    "BATCH_SIZE = 2**6\n",
    "MAX_SEQ_LENGTH = 256\n",
    "LEARNING_RATE = 3e-5\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0517f53-d48c-4f94-a758-809124c81f45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchtext in ./.local/lib/python3.8/site-packages (0.14.1)\n",
      "Requirement already satisfied: pyarrow in ./.local/lib/python3.8/site-packages (10.0.1)\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.8/site-packages (4.25.1)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.8/site-packages (from torchtext) (2.28.1)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.8/site-packages (from torchtext) (4.64.1)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.8/site-packages (from torchtext) (1.23.4)\n",
      "Requirement already satisfied: torch==1.13.1 in ./.local/lib/python3.8/site-packages (from torchtext) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./.local/lib/python3.8/site-packages (from torch==1.13.1->torchtext) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./.local/lib/python3.8/site-packages (from torch==1.13.1->torchtext) (11.10.3.66)\n",
      "Requirement already satisfied: typing-extensions in ./.local/lib/python3.8/site-packages (from torch==1.13.1->torchtext) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./.local/lib/python3.8/site-packages (from torch==1.13.1->torchtext) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./.local/lib/python3.8/site-packages (from torch==1.13.1->torchtext) (11.7.99)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchtext) (0.34.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchtext) (45.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./.local/lib/python3.8/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in ./.local/lib/python3.8/site-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.8/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging>=20.0->transformers) (2.4.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->torchtext) (1.25.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./.local/lib/python3.8/site-packages (from requests->torchtext) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchtext) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchtext) (2.8)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext pyarrow transformers structlog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97dfadde-6359-4359-b514-fd30c16b3bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "import gc\n",
    "import structlog\n",
    "\n",
    "GPU = True\n",
    "device = torch.device(\"cuda\" if GPU else \"cpu\")\n",
    "data_path = '/home/ubuntu/'\n",
    "logger = structlog.getLogger()\n",
    "logger.info(f\"Getting started with {GPU=} {device=} {data_path=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0ac24e0-d77c-42b5-bba7-f7ec70be4a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/ubuntu/\u001b[00m\n",
      "├── \u001b[01;31mparquet_data.zip\u001b[00m\n",
      "├── \u001b[01;34msnap\u001b[00m\n",
      "│   └── \u001b[01;34mnvtop\u001b[00m\n",
      "│       ├── \u001b[01;34m66\u001b[00m\n",
      "│       ├── \u001b[01;34mcommon\u001b[00m\n",
      "│       └── \u001b[01;36mcurrent\u001b[00m -> \u001b[01;34m66\u001b[00m\n",
      "├── test_df.parquet\n",
      "├── train_df.parquet\n",
      "├── try1.ipynb\n",
      "└── val_df.parquet\n",
      "\n",
      "5 directories, 5 files\n"
     ]
    }
   ],
   "source": [
    "!tree /home/ubuntu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd25c11f-dcc0-4400-aca8-500e3e58a6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1086741, 5), (126171, 5), (126171, 5))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_parquet(data_path + 'train_df.parquet')\n",
    "test_df = pd.read_parquet(data_path + 'test_df.parquet')\n",
    "val_df = pd.read_parquet(data_path + 'val_df.parquet')\n",
    "train_df.shape, test_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0c47a72-5601-443e-b947-3b9bb9ba9e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.13.1+cu117', '0.14.1')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__, torchtext.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1757ff69-2684-4b11-9bf5-9f6a5f8a7f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[-1.8532e+01, -1.9899e+01, -1.9202e+01, -1.9233e+01, -2.1818e+01,\n",
       "          -3.3183e-01, -4.3617e-01, -1.6150e-01, -2.5575e-02, -1.2855e+00,\n",
       "           4.6539e-01, -1.3698e+00,  2.5481e-02,  1.3961e+00, -2.3760e+00,\n",
       "          -2.5161e-01, -6.2316e-01, -9.2688e-01, -8.8103e-01, -1.4678e+00,\n",
       "          -1.6217e+00,  3.2145e+00, -2.0604e+00, -4.5068e-01,  4.5483e-01,\n",
       "          -3.9251e+00, -1.8108e+01, -1.8154e+01, -1.8443e+01, -1.8931e+01],\n",
       "         [-2.1589e+01, -2.1636e+01, -2.1418e+01, -2.1295e+01, -2.2876e+01,\n",
       "          -8.4695e-01, -8.1240e-01,  7.8902e-01, -1.7455e+00, -1.4653e+00,\n",
       "           5.6490e-01, -1.1674e+00,  1.2356e+00,  4.1438e+00, -2.4756e+00,\n",
       "           2.0495e+00, -1.3056e+00,  7.8864e-01,  1.2412e+00, -2.7056e+00,\n",
       "          -1.4608e+00, -3.3685e-01, -2.7666e+00,  2.4256e-01,  3.9161e+00,\n",
       "          -6.9252e+00, -2.1043e+01, -2.1170e+01, -2.0820e+01, -2.1201e+01],\n",
       "         [-2.1355e+01, -2.0936e+01, -2.0803e+01, -1.9996e+01, -2.2508e+01,\n",
       "          -1.0702e+00, -1.2807e+00,  8.0083e-01, -2.5328e+00, -2.0794e+00,\n",
       "          -7.4695e-02, -2.3765e+00, -8.2487e-02,  7.4417e+00, -2.5173e+00,\n",
       "          -2.1427e-01, -4.9526e-01, -8.6128e-01,  4.1846e-01, -2.9880e+00,\n",
       "          -2.2347e+00, -1.0304e+00, -2.0541e+00,  3.1538e-01,  3.7330e+00,\n",
       "          -6.5409e+00, -2.0793e+01, -2.0568e+01, -2.0238e+01, -2.0369e+01],\n",
       "         [-2.0309e+01, -2.1225e+01, -2.0786e+01, -2.1611e+01, -2.2968e+01,\n",
       "          -6.3732e-01, -1.3872e+00,  5.2063e-01, -1.9765e+00, -2.2919e+00,\n",
       "           2.1752e-01, -1.3139e+00, -3.5396e-01,  4.5471e+00, -2.6896e+00,\n",
       "          -4.1946e-01, -7.7500e-01, -9.1249e-01, -4.1802e-01, -1.5727e+00,\n",
       "          -1.8177e+00, -1.3429e+00, -1.4203e+00,  1.6126e+00,  6.4946e+00,\n",
       "          -6.4191e+00, -2.1311e+01, -2.0745e+01, -2.0646e+01, -2.0351e+01],\n",
       "         [-2.0537e+01, -2.1130e+01, -2.0580e+01, -2.1501e+01, -2.3339e+01,\n",
       "          -1.2329e-01, -1.4036e+00, -4.4960e-01, -1.8578e+00, -2.2360e+00,\n",
       "           2.5257e-01, -1.3333e+00,  3.5623e-01,  3.7940e+00, -3.2670e+00,\n",
       "           5.4703e-01, -3.9180e-01, -4.6327e-01,  2.8046e-01, -1.2187e+00,\n",
       "          -1.7014e+00, -4.2954e-01, -2.4735e+00,  5.4795e-01,  7.8722e+00,\n",
       "          -6.0718e+00, -2.0745e+01, -2.0331e+01, -2.0259e+01, -2.0217e+01],\n",
       "         [-2.1681e+01, -2.1723e+01, -2.1198e+01, -2.0857e+01, -2.3232e+01,\n",
       "          -4.7492e-01, -1.7424e+00, -8.1062e-01, -2.1330e+00, -2.0256e+00,\n",
       "           5.8700e-01, -6.6166e-01,  2.3291e+00,  4.6294e+00, -3.7499e+00,\n",
       "           1.4300e+00, -1.6061e+00,  8.1381e-01,  2.5701e+00, -2.5303e+00,\n",
       "          -1.6739e+00,  5.9004e-01, -2.6787e+00, -2.1176e-01,  4.4382e+00,\n",
       "          -6.2795e+00, -2.0782e+01, -2.0877e+01, -2.0428e+01, -2.0842e+01],\n",
       "         [-2.1463e+01, -2.0966e+01, -2.1074e+01, -2.0067e+01, -2.2693e+01,\n",
       "          -6.2267e-01, -7.8163e-01, -9.2801e-02, -2.3375e+00, -1.6929e+00,\n",
       "          -3.6896e-01, -2.4060e+00,  2.4572e-01,  7.2160e+00, -2.4930e+00,\n",
       "           3.9765e-03, -8.6921e-01, -7.7966e-01,  6.9086e-01, -2.8618e+00,\n",
       "          -2.5252e+00, -6.8937e-01, -2.5183e+00, -3.7424e-01,  3.2148e+00,\n",
       "          -6.9142e+00, -2.0618e+01, -2.0634e+01, -2.0460e+01, -2.0323e+01],\n",
       "         [-2.1726e+01, -2.1593e+01, -2.1576e+01, -1.9898e+01, -2.3151e+01,\n",
       "          -5.6528e-01, -1.4556e+00,  3.5838e-01, -2.6066e+00, -2.4335e+00,\n",
       "           3.1791e-01, -2.3757e+00, -7.8839e-01,  6.8987e+00, -2.9696e+00,\n",
       "          -3.6685e-01, -4.6606e-01, -1.2922e+00, -1.1873e-01, -1.9211e+00,\n",
       "          -1.7726e+00, -1.3445e+00, -2.2835e+00,  1.2320e+00,  4.1059e+00,\n",
       "          -6.9427e+00, -2.1245e+01, -2.1350e+01, -2.0804e+01, -2.1145e+01],\n",
       "         [-2.1187e+01, -2.0810e+01, -2.0729e+01, -2.0024e+01, -2.2602e+01,\n",
       "          -1.3754e+00, -1.4733e+00,  6.6327e-01, -2.4095e+00, -2.2636e+00,\n",
       "          -9.5332e-02, -2.3874e+00, -6.3662e-01,  6.8972e+00, -2.7144e+00,\n",
       "          -2.5882e-01, -6.1134e-01, -9.7689e-01, -6.1487e-02, -2.5422e+00,\n",
       "          -1.5595e+00, -1.1254e+00, -2.4075e+00,  1.1938e+00,  4.7308e+00,\n",
       "          -5.6066e+00, -2.0731e+01, -2.0477e+01, -1.9745e+01, -2.0288e+01],\n",
       "         [-2.0119e+01, -2.1027e+01, -2.0624e+01, -2.1367e+01, -2.2992e+01,\n",
       "          -7.2403e-01, -1.0803e+00,  1.0500e-01, -1.5964e+00, -2.2548e+00,\n",
       "           2.8500e-01, -1.0511e+00,  3.9716e-02,  3.7723e+00, -2.5312e+00,\n",
       "           2.3228e-01, -9.1369e-01, -5.8183e-01, -4.7033e-01, -1.4922e+00,\n",
       "          -1.4813e+00, -8.5359e-01, -2.0409e+00,  1.1805e+00,  6.4085e+00,\n",
       "          -6.3831e+00, -2.1070e+01, -2.0511e+01, -2.0367e+01, -2.0250e+01],\n",
       "         [-2.0845e+01, -2.1030e+01, -2.0904e+01, -2.0538e+01, -2.2470e+01,\n",
       "          -3.4865e-01, -7.7006e-01,  6.4181e-01, -1.5215e+00, -2.1297e+00,\n",
       "           7.3375e-01, -7.7118e-01,  5.2100e-01,  4.2977e+00, -2.7579e+00,\n",
       "           7.3458e-01,  4.5231e-02, -4.6088e-01,  2.8464e-01, -1.7713e+00,\n",
       "          -1.0256e+00, -3.5819e-01, -1.7903e+00,  7.8434e-01,  3.9020e+00,\n",
       "          -5.8730e+00, -2.0613e+01, -2.0840e+01, -2.0357e+01, -2.0624e+01]]],\n",
       "       device='cuda:0'), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load protbert model\n",
    "from transformers import BertForMaskedLM, BertTokenizer, pipeline\n",
    "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "protbert_model = BertForMaskedLM.from_pretrained(\"Rostlab/prot_bert\")\n",
    "if GPU:\n",
    "    protbert_model.cuda()\n",
    "import torch\n",
    "import re\n",
    "\n",
    "\n",
    "x_aminos = re.compile(\"[UZOB]\")\n",
    "\n",
    "def prepare_input(seq, **tokenizer_args):\n",
    "    seq = x_aminos.sub(\"X\", ' '.join(seq))\n",
    "    input_ids = tokenizer.encode(seq, add_special_tokens=True, **tokenizer_args)\n",
    "    return input_ids\n",
    "\n",
    "def get_embeddings(seq, **tokenizer_args):\n",
    "    input_ids = prepare_input(seq, **tokenizer_args)\n",
    "    input_ids = torch.tensor([input_ids], device='cuda' if GPU else 'cpu')\n",
    "    with torch.no_grad():\n",
    "        return protbert_model(input_ids)\n",
    "\n",
    "eg_input = get_embeddings(\"RRWWRRRRW\")\n",
    "eg_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61185c77-fda0-4d24-b105-8f36aacf238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ProteinSequenceDataset(Dataset):\n",
    "    def __init__(self, df, sequence_col='sequence', label_col='family_id', max_len=100):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.sequence_col = sequence_col\n",
    "        self.label_col = label_col\n",
    "        self.max_len = max_len\n",
    "        self._label_translator = {l: torch.tensor(i, device='cuda' if GPU else 'cpu') for i, l in enumerate(sorted(df[label_col].unique()))}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        seq, label = row[self.sequence_col], row[self.label_col]\n",
    "        # Convert to tensor\n",
    "        seq = prepare_input(seq[:self.max_len-10], padding='max_length', max_length=self.max_len)\n",
    "        seq = torch.tensor(seq, device='cuda' if GPU else 'cpu')\n",
    "        label = self._label_translator[label]\n",
    "        return seq, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15141a59-5d42-4c64-9e38-3ac9ef56a725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Methyltransf_25', 0),\n",
       " ('LRR_1', 1),\n",
       " ('Acetyltransf_7', 2),\n",
       " ('His_kinase', 3),\n",
       " ('Bac_transf', 4)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Convert train and test to same top n families\n",
    "top_families = train_df['family_id'].value_counts()[:NUM_CLASSES]\n",
    "# Convert to numbers\n",
    "fam2id = {fam: i for i, fam in enumerate(top_families.index)}\n",
    "list(fam2id.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2d8c6e5-3db4-4d27-954e-510a12a12b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 647,248/1,086,741 = 59.558625% of rows due to nan famid num.\n",
      "Removing 71,793/126,171 = 56.901348% of rows due to nan famid num.\n",
      "Removing 71,793/126,171 = 56.901348% of rows due to nan famid num.\n"
     ]
    }
   ],
   "source": [
    "def add_and_filter_family_id(df):\n",
    "    df['family_code'] = df['family_id'].apply(lambda x: fam2id.get(x, np.nan))\n",
    "    logger.info(f'Removing {df[\"family_code\"].isna().sum():,}/{len(df):,} = {df[\"family_code\"].isna().mean()*100:,.6f}% of rows due to nan famid num.')\n",
    "    return df.dropna(subset='family_code').reset_index(drop=True)\n",
    "\n",
    "train_df = add_and_filter_family_id(train_df)\n",
    "test_df = add_and_filter_family_id(test_df)\n",
    "val_df = add_and_filter_family_id(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7de3d469-98c2-47bb-b293-83b96ba054bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((439493, 6), (54378, 6), (54378, 6))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc; gc.collect()\n",
    "train_df.shape, test_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86a78873-120b-465c-b442-3eacc8ddcd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2, 14, 16,  ...,  0,  0,  0],\n",
       "         [ 2,  6,  5,  ...,  0,  0,  0],\n",
       "         [ 2,  8, 15,  ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 2, 14, 12,  ...,  0,  0,  0],\n",
       "         [ 2,  5, 19,  ...,  0,  0,  0],\n",
       "         [ 2, 16, 10,  ...,  0,  0,  0]], device='cuda:0'),\n",
       " tensor([433, 289, 117, 749, 215,  85,  59,  31,  63, 185, 494,  46, 986, 298,\n",
       "         383, 107, 865, 314, 164, 441, 337, 199, 413, 348, 320, 367, 688, 223,\n",
       "         618, 392, 541, 906,  65, 454, 831, 423, 229, 259, 465, 468,  14,  43,\n",
       "          11, 178,   8,  81, 417,  33,  55, 489, 721, 962, 875, 601, 174, 350,\n",
       "         747, 161, 257, 367,  35, 277, 228,  64], device='cuda:0'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = ProteinSequenceDataset(train_df, label_col='family_code', max_len=MAX_SEQ_LENGTH)\n",
    "test_dataset  = ProteinSequenceDataset(test_df, label_col='family_code', max_len=MAX_SEQ_LENGTH)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "train_features, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60b661f4-58ff-4fc6-bf3b-f6ddb1291890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer models from tutorial https://n8henrie.com/2021/08/writing-a-transformer-classifier-in-pytorch/\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, vocab_size=5000, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(vocab_size, d_model)\n",
    "        position = torch.arange(0, vocab_size, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float()\n",
    "            * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, : x.size(1), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Text classifier based on a pytorch TransformerEncoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embeddings,\n",
    "        vocab_size=30,\n",
    "        embedding_size=1024,\n",
    "        nhead=8,\n",
    "        dim_feedforward=2048,\n",
    "        num_layers=6,\n",
    "        num_labels=2,\n",
    "        dropout=0.1,\n",
    "        activation=\"relu\",\n",
    "        classifier_dropout=0.1,\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        d_model = embedding_size\n",
    "        assert d_model % nhead == 0, \"nheads must divide evenly into d_model\"\n",
    "\n",
    "        self.emb = embeddings\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(\n",
    "            d_model=d_model,\n",
    "            dropout=dropout,\n",
    "            vocab_size=vocab_size,\n",
    "        )\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.classifier = nn.Linear(d_model, num_labels)\n",
    "        self.d_model = d_model\n",
    "        self._agg_type = 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            embeds = self.emb(x)\n",
    "            # x = embeds[:,-10:,:] # Only need last ten\n",
    "            x = embeds\n",
    "        # x = self.emb(x) * math.sqrt(self.d_model)\n",
    "        # x = self.pos_encoder(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        if self._agg_type == 0:\n",
    "            x = x[:, -1, :]\n",
    "        else:\n",
    "            x = x.mean(1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8daf6b2c-ca01-4ea8-a85f-16da306e909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model = Net(\n",
    "    protbert_model.bert.embeddings,\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    nhead=8,  # the number of heads in the multiheadattention models\n",
    "    dim_feedforward=50,  # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "    num_layers=6,\n",
    "    num_labels=NUM_CLASSES,\n",
    "    dropout=0.2,\n",
    "    classifier_dropout=0.2,\n",
    ").to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    tf_model.parameters(), lr=LEARNING_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29f2d969-34b8-4b00-9b04-6908554c04e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9b34e7f-27fe-4fb0-94cf-1635e8d93a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, log_n=100):\n",
    "    epoch_loss = 0\n",
    "    epoch_correct = 0\n",
    "    epoch_count = 0\n",
    "    for idx, (inputs, labels) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predictions = tf_model(inputs)\n",
    "        loss = loss_fn(predictions, labels)\n",
    "\n",
    "        correct = predictions.argmax(axis=1) == labels\n",
    "        acc = correct.sum().item() / correct.size(0)\n",
    "        epoch_correct += correct.sum().item()\n",
    "        epoch_count += correct.size(0)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if idx % log_n == log_n-1:\n",
    "            logger.info(f'{epoch=} {idx:,}/{len(train_dataloader):,} {epoch_loss=:,.6f}/{epoch_count=:,} = {epoch_loss/epoch_count:,.6f} {epoch_correct:,}/{epoch_count:,} = {100*epoch_correct/epoch_count:,.6f}%')\n",
    "\n",
    "    logger.info(f\"{epoch=} {epoch_loss=}\")\n",
    "    logger.info(f\"{epoch=} accuracy: {epoch_correct / epoch_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0af25e-fc30-41de-b483-cb9a1a1f3544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_epoch(epoch, log_n=100):\n",
    "    with torch.no_grad():\n",
    "        test_epoch_loss = 0\n",
    "        test_epoch_correct = 0\n",
    "        test_epoch_count = 0\n",
    "\n",
    "        for idx, (inputs, labels) in enumerate(test_dataloader):\n",
    "            predictions = tf_model(inputs)\n",
    "            test_loss = loss_fn(predictions, labels)\n",
    "\n",
    "            correct = predictions.argmax(axis=1) == labels\n",
    "            acc = correct.sum().item() / correct.size(0)\n",
    "\n",
    "            test_epoch_correct += correct.sum().item()\n",
    "            test_epoch_count += correct.size(0)\n",
    "            test_epoch_loss += loss.item()\n",
    "            \n",
    "            if idx % log_n == log_n-1:\n",
    "                logger.info(f'{epoch=} {idx:,}/{len(test_dataloader):,} {test_epoch_loss=:,.6f}/{test_epoch_count=:,} = {test_epoch_loss/test_epoch_count:,.6f} {test_epoch_correct:,}/{test_epoch_count:,} = {100*test_epoch_correct/test_epoch_count:,.6f}%')\n",
    "\n",
    "    logger.info(f\"{epoch=} {test_epoch_loss=}\")\n",
    "    logger.info(f\"test {epoch=} accuracy: {test_epoch_correct=:,}/{test_epoch_count:,} = {100 * test_epoch_correct / test_epoch_count:,.6f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55360f7f-cb55-4b3f-825b-3c4013fd7cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: structlog in ./.local/lib/python3.8/site-packages (22.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "2023-01-21 17:49:56 [info     ] starting\n",
      "2023-01-21 17:49:56 [info     ] epoch=0\n",
      "2023-01-21 17:50:28 [info     ] epoch=0 99 / 6868 epoch_loss/epoch_count=0.095014 107/6,400\n",
      "2023-01-21 17:51:01 [info     ] epoch=0 199 / 6868 epoch_loss/epoch_count=0.094684 241/12,800\n",
      "2023-01-21 17:51:35 [info     ] epoch=0 299 / 6868 epoch_loss/epoch_count=0.094513 354/19,200\n",
      "2023-01-21 17:52:08 [info     ] epoch=0 399 / 6868 epoch_loss/epoch_count=0.094286 479/25,600\n",
      "2023-01-21 17:52:41 [info     ] epoch=0 499 / 6868 epoch_loss/epoch_count=0.094081 603/32,000\n",
      "2023-01-21 17:53:15 [info     ] epoch=0 599 / 6868 epoch_loss/epoch_count=0.093854 724/38,400\n",
      "2023-01-21 17:53:48 [info     ] epoch=0 699 / 6868 epoch_loss/epoch_count=0.093696 853/44,800\n",
      "2023-01-21 17:54:22 [info     ] epoch=0 799 / 6868 epoch_loss/epoch_count=0.093532 961/51,200\n",
      "2023-01-21 17:54:55 [info     ] epoch=0 899 / 6868 epoch_loss/epoch_count=0.093328 1,087/57,600\n",
      "2023-01-21 17:55:29 [info     ] epoch=0 999 / 6868 epoch_loss/epoch_count=0.093155 1,208/64,000\n",
      "2023-01-21 17:56:03 [info     ] epoch=0 1099 / 6868 epoch_loss/epoch_count=0.092982 1,335/70,400\n",
      "2023-01-21 17:56:36 [info     ] epoch=0 1199 / 6868 epoch_loss/epoch_count=0.092796 1,465/76,800\n",
      "2023-01-21 17:57:10 [info     ] epoch=0 1299 / 6868 epoch_loss/epoch_count=0.092617 1,604/83,200\n",
      "2023-01-21 17:57:43 [info     ] epoch=0 1399 / 6868 epoch_loss/epoch_count=0.092449 1,751/89,600\n",
      "2023-01-21 17:58:17 [info     ] epoch=0 1499 / 6868 epoch_loss/epoch_count=0.092303 1,875/96,000\n",
      "2023-01-21 17:58:51 [info     ] epoch=0 1599 / 6868 epoch_loss/epoch_count=0.092137 2,015/102,400\n",
      "2023-01-21 17:59:25 [info     ] epoch=0 1699 / 6868 epoch_loss/epoch_count=0.091986 2,158/108,800\n",
      "2023-01-21 17:59:58 [info     ] epoch=0 1799 / 6868 epoch_loss/epoch_count=0.091838 2,308/115,200\n",
      "2023-01-21 18:00:32 [info     ] epoch=0 1899 / 6868 epoch_loss/epoch_count=0.091703 2,445/121,600\n",
      "2023-01-21 18:01:05 [info     ] epoch=0 1999 / 6868 epoch_loss/epoch_count=0.091558 2,585/128,000\n",
      "2023-01-21 18:01:39 [info     ] epoch=0 2099 / 6868 epoch_loss/epoch_count=0.091420 2,745/134,400\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-930e1f50f6e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mepoch_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mepoch_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-d2724f6b852b>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Convert to tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mGPU\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_translator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-cd5af3a6601e>\u001b[0m in \u001b[0;36mprepare_input\u001b[0;34m(seq, **tokenizer_args)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtokenizer_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_aminos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtokenizer_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m   2289\u001b[0m                 method).\n\u001b[1;32m   2290\u001b[0m         \"\"\"\n\u001b[0;32m-> 2291\u001b[0;31m         encoded_inputs = self.encode_plus(\n\u001b[0m\u001b[1;32m   2292\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2293\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2697\u001b[0m         )\n\u001b[1;32m   2698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2699\u001b[0;31m         return self._encode_plus(\n\u001b[0m\u001b[1;32m   2700\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2701\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m             )\n\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m                 \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m                 \u001b[0mtokenized_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                 \u001b[0mtokenized_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;31m# [\"This\", \" is\", \" something\", \"<special_token_1>\", \"else\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36m_tokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    248\u001b[0m                     \u001b[0msplit_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                     \u001b[0msplit_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwordpiece_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0msplit_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwordpiece_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    555\u001b[0m                 \u001b[0mcur_substr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m                     \u001b[0msubstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m                         \u001b[0msubstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"##\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msubstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "# with torch.autocast(device_type='cuda' if GPU else 'cpu'):\n",
    "for epoch in range(EPOCHS):\n",
    "    logger.info(f\"{epoch=}\")\n",
    "    train_one_epoch(epoch)\n",
    "    test_one_epoch(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fc4fd8-e0fd-4808-b057-140788504bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-21 18:02:38 [info     ] epoch=0 29/850 test_epoch_loss=173.171411/test_epoch_count=1,920 = 0.090193 50/1,920 = 2.604167%\n",
      "2023-01-21 18:02:43 [info     ] epoch=0 59/850 test_epoch_loss=346.342821/test_epoch_count=3,840 = 0.090193 103/3,840 = 2.682292%\n",
      "2023-01-21 18:02:47 [info     ] epoch=0 89/850 test_epoch_loss=519.514232/test_epoch_count=5,760 = 0.090193 157/5,760 = 2.725694%\n",
      "2023-01-21 18:02:52 [info     ] epoch=0 119/850 test_epoch_loss=692.685642/test_epoch_count=7,680 = 0.090193 207/7,680 = 2.695312%\n",
      "2023-01-21 18:02:57 [info     ] epoch=0 149/850 test_epoch_loss=865.857053/test_epoch_count=9,600 = 0.090193 256/9,600 = 2.666667%\n",
      "2023-01-21 18:03:01 [info     ] epoch=0 179/850 test_epoch_loss=1,039.028463/test_epoch_count=11,520 = 0.090193 304/11,520 = 2.638889%\n",
      "2023-01-21 18:03:06 [info     ] epoch=0 209/850 test_epoch_loss=1,212.199874/test_epoch_count=13,440 = 0.090193 353/13,440 = 2.626488%\n",
      "2023-01-21 18:03:10 [info     ] epoch=0 239/850 test_epoch_loss=1,385.371284/test_epoch_count=15,360 = 0.090193 405/15,360 = 2.636719%\n",
      "2023-01-21 18:03:15 [info     ] epoch=0 269/850 test_epoch_loss=1,558.542695/test_epoch_count=17,280 = 0.090193 443/17,280 = 2.563657%\n",
      "2023-01-21 18:03:20 [info     ] epoch=0 299/850 test_epoch_loss=1,731.714106/test_epoch_count=19,200 = 0.090193 505/19,200 = 2.630208%\n",
      "2023-01-21 18:03:24 [info     ] epoch=0 329/850 test_epoch_loss=1,904.885516/test_epoch_count=21,120 = 0.090193 556/21,120 = 2.632576%\n",
      "2023-01-21 18:03:29 [info     ] epoch=0 359/850 test_epoch_loss=2,078.056927/test_epoch_count=23,040 = 0.090193 606/23,040 = 2.630208%\n",
      "2023-01-21 18:03:34 [info     ] epoch=0 389/850 test_epoch_loss=2,251.228337/test_epoch_count=24,960 = 0.090193 653/24,960 = 2.616186%\n",
      "2023-01-21 18:03:38 [info     ] epoch=0 419/850 test_epoch_loss=2,424.399748/test_epoch_count=26,880 = 0.090193 701/26,880 = 2.607887%\n",
      "2023-01-21 18:03:43 [info     ] epoch=0 449/850 test_epoch_loss=2,597.571158/test_epoch_count=28,800 = 0.090193 747/28,800 = 2.593750%\n"
     ]
    }
   ],
   "source": [
    "test_one_epoch(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f3caeee-9f72-4502-873b-929d057a6a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2, 19,  9,  ...,  0,  0,  0],\n",
      "        [ 2,  6,  6,  ...,  0,  0,  0],\n",
      "        [ 2, 16,  8,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [ 2, 20, 12,  ...,  0,  0,  0],\n",
      "        [ 2, 11, 21,  ...,  0,  0,  0],\n",
      "        [ 2,  6, 23,  ...,  0,  0,  0]], device='cuda:0')\n",
      "tensor([[-0.0440, -5.3381, -0.9999,  ...,  1.2580,  1.1968, -0.1832],\n",
      "        [-0.5925, -5.6488, -1.5915,  ...,  1.4442,  1.2875,  0.3802],\n",
      "        [ 3.4140,  0.9251,  3.1872,  ..., -1.3907, -0.8055, -2.7464],\n",
      "        ...,\n",
      "        [ 2.4615,  2.9081,  2.8831,  ..., -1.6114, -1.2116, -2.2700],\n",
      "        [ 3.4396,  0.9174,  3.2128,  ..., -1.4100, -0.7952, -2.7663],\n",
      "        [-3.4412, -1.6198, -3.4318,  ...,  1.0870,  0.4103,  2.9897]],\n",
      "       device='cuda:0')\n",
      "tensor(5.6799, device='cuda:0')\n",
      "tensor([ 4,  4,  0, 47, 47,  0, 47,  7,  0,  3,  4, 12,  0,  2, 16, 47,  1,  0,\n",
      "         0,  0,  0, 47,  0,  3,  4,  0,  4,  0,  3,  0,  0,  0,  2, 12,  4,  0,\n",
      "         0,  7,  0,  0, 47,  0,  0, 47, 47,  2,  0,  2, 47, 47,  0, 47,  0,  0,\n",
      "         0,  0,  0, 12,  1, 47, 47, 38,  0, 47], device='cuda:0')\n",
      "tensor([556, 412, 910, 716, 834, 756, 486, 303, 185, 934,  24, 232, 516, 380,\n",
      "         59, 577, 176, 645, 308, 375,  68, 891, 286,  35, 727,   2, 373, 976,\n",
      "        550, 364,   0, 100, 913, 921,   4, 121, 371, 445, 107,  88, 691, 762,\n",
      "          2, 450, 644, 702, 288, 116, 150, 381, 593, 985, 300,   3, 285, 114,\n",
      "        246,  95, 351, 152, 148, 140, 387, 388], device='cuda:0')\n",
      "tensor([[ 2, 17, 14,  ...,  0,  0,  0],\n",
      "        [ 2,  8,  9,  ...,  0,  0,  0],\n",
      "        [ 2,  8, 11,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [ 2, 10, 19,  ...,  0,  0,  0],\n",
      "        [ 2, 14,  8,  ...,  0,  0,  0],\n",
      "        [ 2,  5, 19,  ...,  0,  0,  0]], device='cuda:0')\n",
      "tensor([[-2.1035, -3.6559, -2.5492,  ...,  1.3076,  0.8787,  1.7513],\n",
      "        [ 2.5221,  2.7949,  2.8812,  ..., -1.6095, -1.1952, -2.3280],\n",
      "        [-3.3094, -1.7706, -3.3902,  ...,  1.0708,  0.4321,  2.9613],\n",
      "        ...,\n",
      "        [-0.4641, -5.0898, -1.2701,  ...,  1.3190,  1.1786,  0.1023],\n",
      "        [ 3.9131, -0.6407,  3.2264,  ..., -1.1441, -0.4575, -2.9701],\n",
      "        [-3.1041, -2.1983, -3.2975,  ...,  1.1143,  0.5045,  2.8489]],\n",
      "       device='cuda:0')\n",
      "tensor(5.5846, device='cuda:0')\n",
      "tensor([16, 38, 47,  1, 47, 47,  4,  0,  0,  0,  4,  0,  3, 47, 47,  0,  0,  3,\n",
      "         1,  7,  0,  1,  7,  0,  0, 47, 47,  0,  0,  1,  0, 12,  1,  0,  0,  0,\n",
      "         4,  0, 47,  0,  0,  0, 47,  7,  4, 47,  7,  0,  0,  7,  0,  4,  0,  1,\n",
      "        47, 47,  0,  0, 16,  0,  0,  4,  0, 47], device='cuda:0')\n",
      "tensor([214, 468,  81, 839, 171,  69, 236, 459, 274, 293,  78, 154,  17, 670,\n",
      "        148, 285, 504, 584, 102, 558,  57, 538,   7, 500,  89,  69, 111, 143,\n",
      "        774, 441, 573, 252, 820, 490, 682,  22, 981,  15, 716, 115, 308, 557,\n",
      "        144,  20, 754,  83, 125, 583,   3, 705, 664, 589,  94, 366, 306, 310,\n",
      "        824,  43, 904,   6,   2, 754, 530, 706], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Verify its not just giving the same label or getting lucky\n",
    "with torch.no_grad():\n",
    "    test_epoch_loss = 0\n",
    "    test_epoch_correct = 0\n",
    "    test_epoch_count = 0\n",
    "    for idx, (inputs, labels) in enumerate(test_dataloader):\n",
    "        predictions = tf_model(inputs)\n",
    "        test_loss = loss_fn(predictions, labels)\n",
    "        print(inputs)\n",
    "        print(predictions)\n",
    "        print(test_loss)\n",
    "        print(predictions.argmax(axis=1))\n",
    "        print(labels)\n",
    "        if idx * BATCH_SIZE > 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc29a6e8-0591-4a91-994e-a9d07d9821c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0549c42d-63f6-4846-b999-7cd451151c93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
